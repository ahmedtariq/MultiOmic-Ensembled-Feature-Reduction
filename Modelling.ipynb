{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_control = pd.read_csv('Data\\Input\\scaledcontrol.csv')\n",
    "DF_prediabetic = pd.read_csv('Data\\Input\\scaledprediabetic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 1060)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_control.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deseq_A1BG-AS1</th>\n",
       "      <th>Deseq_ABHD1</th>\n",
       "      <th>Deseq_ABLIM1</th>\n",
       "      <th>Deseq_ACADVL</th>\n",
       "      <th>Deseq_ACAT2</th>\n",
       "      <th>Deseq_ACOT8</th>\n",
       "      <th>Deseq_ACPT</th>\n",
       "      <th>Deseq_ACSM3</th>\n",
       "      <th>Deseq_ACTB</th>\n",
       "      <th>Deseq_ACTG1</th>\n",
       "      <th>...</th>\n",
       "      <th>PDGFBB</th>\n",
       "      <th>VEGF</th>\n",
       "      <th>LEPTIN</th>\n",
       "      <th>PAI1</th>\n",
       "      <th>CD40L</th>\n",
       "      <th>ENA78</th>\n",
       "      <th>CHEX1</th>\n",
       "      <th>CHEX2</th>\n",
       "      <th>CHEX3</th>\n",
       "      <th>CHEX4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.333335e-11</td>\n",
       "      <td>-8.333332e-11</td>\n",
       "      <td>1.250001e-10</td>\n",
       "      <td>-4.625929e-18</td>\n",
       "      <td>4.166671e-11</td>\n",
       "      <td>8.333333e-11</td>\n",
       "      <td>-8.333332e-11</td>\n",
       "      <td>-1.250000e-10</td>\n",
       "      <td>8.333341e-11</td>\n",
       "      <td>1.850372e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.166661e-11</td>\n",
       "      <td>8.333332e-11</td>\n",
       "      <td>-2.775558e-17</td>\n",
       "      <td>1.850372e-17</td>\n",
       "      <td>4.166662e-11</td>\n",
       "      <td>-4.166669e-11</td>\n",
       "      <td>4.166667e-11</td>\n",
       "      <td>4.166667e-11</td>\n",
       "      <td>2.197316e-17</td>\n",
       "      <td>4.166666e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "      <td>1.021508e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.994497e+00</td>\n",
       "      <td>-2.318050e+00</td>\n",
       "      <td>-5.748429e-01</td>\n",
       "      <td>-2.472519e+00</td>\n",
       "      <td>-2.997341e+00</td>\n",
       "      <td>-2.198168e+00</td>\n",
       "      <td>-2.260413e+00</td>\n",
       "      <td>-2.091102e+00</td>\n",
       "      <td>-1.760498e+00</td>\n",
       "      <td>-1.728233e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.307165e+00</td>\n",
       "      <td>-1.456195e+00</td>\n",
       "      <td>-1.878508e+00</td>\n",
       "      <td>-2.506237e+00</td>\n",
       "      <td>-1.891588e+00</td>\n",
       "      <td>-1.580934e+00</td>\n",
       "      <td>-1.406704e+00</td>\n",
       "      <td>-2.073942e+00</td>\n",
       "      <td>-2.503969e+00</td>\n",
       "      <td>-1.660176e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.238398e-01</td>\n",
       "      <td>-6.051293e-01</td>\n",
       "      <td>-5.748429e-01</td>\n",
       "      <td>-8.380472e-01</td>\n",
       "      <td>-5.763414e-01</td>\n",
       "      <td>-6.032149e-01</td>\n",
       "      <td>-4.779981e-01</td>\n",
       "      <td>-5.251766e-01</td>\n",
       "      <td>-5.368419e-01</td>\n",
       "      <td>-6.163841e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.702344e-01</td>\n",
       "      <td>-6.514043e-01</td>\n",
       "      <td>-7.858469e-01</td>\n",
       "      <td>-1.926771e-01</td>\n",
       "      <td>-6.206632e-01</td>\n",
       "      <td>-7.017757e-01</td>\n",
       "      <td>-6.605077e-01</td>\n",
       "      <td>-5.795105e-01</td>\n",
       "      <td>-2.020041e-01</td>\n",
       "      <td>-5.848699e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.087853e-01</td>\n",
       "      <td>1.780226e-01</td>\n",
       "      <td>-5.748429e-01</td>\n",
       "      <td>-5.654668e-02</td>\n",
       "      <td>1.268710e-01</td>\n",
       "      <td>-1.093999e-01</td>\n",
       "      <td>6.851838e-02</td>\n",
       "      <td>1.982166e-01</td>\n",
       "      <td>-2.385329e-01</td>\n",
       "      <td>1.822928e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.384345e-01</td>\n",
       "      <td>-2.468410e-01</td>\n",
       "      <td>-2.240631e-01</td>\n",
       "      <td>3.468029e-01</td>\n",
       "      <td>2.765918e-01</td>\n",
       "      <td>-2.862124e-01</td>\n",
       "      <td>-4.490995e-01</td>\n",
       "      <td>-1.183229e-02</td>\n",
       "      <td>1.793038e-01</td>\n",
       "      <td>-7.349627e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.992805e-01</td>\n",
       "      <td>5.951477e-01</td>\n",
       "      <td>3.380548e-01</td>\n",
       "      <td>7.739467e-01</td>\n",
       "      <td>5.943826e-01</td>\n",
       "      <td>4.178596e-01</td>\n",
       "      <td>5.536500e-01</td>\n",
       "      <td>6.941103e-01</td>\n",
       "      <td>5.246193e-01</td>\n",
       "      <td>4.285902e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.813775e-01</td>\n",
       "      <td>3.995589e-01</td>\n",
       "      <td>8.915151e-01</td>\n",
       "      <td>6.916813e-01</td>\n",
       "      <td>7.612175e-01</td>\n",
       "      <td>7.587347e-01</td>\n",
       "      <td>4.175630e-01</td>\n",
       "      <td>6.934506e-01</td>\n",
       "      <td>4.515786e-01</td>\n",
       "      <td>3.662051e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.367392e+00</td>\n",
       "      <td>2.494230e+00</td>\n",
       "      <td>2.923344e+00</td>\n",
       "      <td>1.679812e+00</td>\n",
       "      <td>2.163745e+00</td>\n",
       "      <td>2.897540e+00</td>\n",
       "      <td>2.075615e+00</td>\n",
       "      <td>2.521142e+00</td>\n",
       "      <td>2.979411e+00</td>\n",
       "      <td>2.756359e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611809e+00</td>\n",
       "      <td>2.590826e+00</td>\n",
       "      <td>1.376017e+00</td>\n",
       "      <td>9.233012e-01</td>\n",
       "      <td>1.463666e+00</td>\n",
       "      <td>1.999098e+00</td>\n",
       "      <td>2.076277e+00</td>\n",
       "      <td>1.670169e+00</td>\n",
       "      <td>1.537224e+00</td>\n",
       "      <td>2.622985e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Deseq_A1BG-AS1   Deseq_ABHD1  Deseq_ABLIM1  Deseq_ACADVL   Deseq_ACAT2  \\\n",
       "count    2.400000e+01  2.400000e+01  2.400000e+01  2.400000e+01  2.400000e+01   \n",
       "mean     8.333335e-11 -8.333332e-11  1.250001e-10 -4.625929e-18  4.166671e-11   \n",
       "std      1.021508e+00  1.021508e+00  1.021508e+00  1.021508e+00  1.021508e+00   \n",
       "min     -1.994497e+00 -2.318050e+00 -5.748429e-01 -2.472519e+00 -2.997341e+00   \n",
       "25%     -4.238398e-01 -6.051293e-01 -5.748429e-01 -8.380472e-01 -5.763414e-01   \n",
       "50%      1.087853e-01  1.780226e-01 -5.748429e-01 -5.654668e-02  1.268710e-01   \n",
       "75%      3.992805e-01  5.951477e-01  3.380548e-01  7.739467e-01  5.943826e-01   \n",
       "max      2.367392e+00  2.494230e+00  2.923344e+00  1.679812e+00  2.163745e+00   \n",
       "\n",
       "        Deseq_ACOT8    Deseq_ACPT   Deseq_ACSM3    Deseq_ACTB   Deseq_ACTG1  \\\n",
       "count  2.400000e+01  2.400000e+01  2.400000e+01  2.400000e+01  2.400000e+01   \n",
       "mean   8.333333e-11 -8.333332e-11 -1.250000e-10  8.333341e-11  1.850372e-17   \n",
       "std    1.021508e+00  1.021508e+00  1.021508e+00  1.021508e+00  1.021508e+00   \n",
       "min   -2.198168e+00 -2.260413e+00 -2.091102e+00 -1.760498e+00 -1.728233e+00   \n",
       "25%   -6.032149e-01 -4.779981e-01 -5.251766e-01 -5.368419e-01 -6.163841e-01   \n",
       "50%   -1.093999e-01  6.851838e-02  1.982166e-01 -2.385329e-01  1.822928e-02   \n",
       "75%    4.178596e-01  5.536500e-01  6.941103e-01  5.246193e-01  4.285902e-01   \n",
       "max    2.897540e+00  2.075615e+00  2.521142e+00  2.979411e+00  2.756359e+00   \n",
       "\n",
       "       ...        PDGFBB          VEGF        LEPTIN          PAI1  \\\n",
       "count  ...  2.400000e+01  2.400000e+01  2.400000e+01  2.400000e+01   \n",
       "mean   ... -4.166661e-11  8.333332e-11 -2.775558e-17  1.850372e-17   \n",
       "std    ...  1.021508e+00  1.021508e+00  1.021508e+00  1.021508e+00   \n",
       "min    ... -1.307165e+00 -1.456195e+00 -1.878508e+00 -2.506237e+00   \n",
       "25%    ... -7.702344e-01 -6.514043e-01 -7.858469e-01 -1.926771e-01   \n",
       "50%    ... -2.384345e-01 -2.468410e-01 -2.240631e-01  3.468029e-01   \n",
       "75%    ...  3.813775e-01  3.995589e-01  8.915151e-01  6.916813e-01   \n",
       "max    ...  2.611809e+00  2.590826e+00  1.376017e+00  9.233012e-01   \n",
       "\n",
       "              CD40L         ENA78         CHEX1         CHEX2         CHEX3  \\\n",
       "count  2.400000e+01  2.400000e+01  2.400000e+01  2.400000e+01  2.400000e+01   \n",
       "mean   4.166662e-11 -4.166669e-11  4.166667e-11  4.166667e-11  2.197316e-17   \n",
       "std    1.021508e+00  1.021508e+00  1.021508e+00  1.021508e+00  1.021508e+00   \n",
       "min   -1.891588e+00 -1.580934e+00 -1.406704e+00 -2.073942e+00 -2.503969e+00   \n",
       "25%   -6.206632e-01 -7.017757e-01 -6.605077e-01 -5.795105e-01 -2.020041e-01   \n",
       "50%    2.765918e-01 -2.862124e-01 -4.490995e-01 -1.183229e-02  1.793038e-01   \n",
       "75%    7.612175e-01  7.587347e-01  4.175630e-01  6.934506e-01  4.515786e-01   \n",
       "max    1.463666e+00  1.999098e+00  2.076277e+00  1.670169e+00  1.537224e+00   \n",
       "\n",
       "              CHEX4  \n",
       "count  2.400000e+01  \n",
       "mean   4.166666e-11  \n",
       "std    1.021508e+00  \n",
       "min   -1.660176e+00  \n",
       "25%   -5.848699e-01  \n",
       "50%   -7.349627e-02  \n",
       "75%    3.662051e-01  \n",
       "max    2.622985e+00  \n",
       "\n",
       "[8 rows x 1059 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_control.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create control label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_control['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 1060)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_prediabetic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deseq_A1BG-AS1</th>\n",
       "      <th>Deseq_ABHD1</th>\n",
       "      <th>Deseq_ABLIM1</th>\n",
       "      <th>Deseq_ACADVL</th>\n",
       "      <th>Deseq_ACAT2</th>\n",
       "      <th>Deseq_ACOT8</th>\n",
       "      <th>Deseq_ACPT</th>\n",
       "      <th>Deseq_ACSM3</th>\n",
       "      <th>Deseq_ACTB</th>\n",
       "      <th>Deseq_ACTG1</th>\n",
       "      <th>...</th>\n",
       "      <th>PDGFBB</th>\n",
       "      <th>VEGF</th>\n",
       "      <th>LEPTIN</th>\n",
       "      <th>PAI1</th>\n",
       "      <th>CD40L</th>\n",
       "      <th>ENA78</th>\n",
       "      <th>CHEX1</th>\n",
       "      <th>CHEX2</th>\n",
       "      <th>CHEX3</th>\n",
       "      <th>CHEX4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>1.530000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.960786e-11</td>\n",
       "      <td>-1.307190e-11</td>\n",
       "      <td>-1.437908e-10</td>\n",
       "      <td>6.535935e-12</td>\n",
       "      <td>-1.307190e-11</td>\n",
       "      <td>-1.307186e-11</td>\n",
       "      <td>3.921568e-11</td>\n",
       "      <td>-2.176908e-18</td>\n",
       "      <td>-1.307195e-11</td>\n",
       "      <td>1.307187e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.960785e-11</td>\n",
       "      <td>-1.960785e-11</td>\n",
       "      <td>1.960783e-11</td>\n",
       "      <td>1.307188e-11</td>\n",
       "      <td>-6.535961e-12</td>\n",
       "      <td>3.267980e-11</td>\n",
       "      <td>6.535948e-12</td>\n",
       "      <td>4.136125e-17</td>\n",
       "      <td>1.307188e-11</td>\n",
       "      <td>5.882351e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "      <td>1.003284e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.245959e+00</td>\n",
       "      <td>-3.339595e+00</td>\n",
       "      <td>-7.502509e-01</td>\n",
       "      <td>-3.299489e+00</td>\n",
       "      <td>-6.268547e+00</td>\n",
       "      <td>-3.645094e+00</td>\n",
       "      <td>-3.262293e+00</td>\n",
       "      <td>-3.484708e+00</td>\n",
       "      <td>-1.769133e+00</td>\n",
       "      <td>-1.277190e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.154743e+00</td>\n",
       "      <td>-1.396494e+00</td>\n",
       "      <td>-1.405611e+00</td>\n",
       "      <td>-2.696910e+00</td>\n",
       "      <td>-5.872800e-01</td>\n",
       "      <td>-6.024036e-01</td>\n",
       "      <td>-1.598719e+00</td>\n",
       "      <td>-2.600563e+00</td>\n",
       "      <td>-2.992404e+00</td>\n",
       "      <td>-2.172262e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.452836e-01</td>\n",
       "      <td>-5.751620e-01</td>\n",
       "      <td>-7.502509e-01</td>\n",
       "      <td>-5.151154e-01</td>\n",
       "      <td>-5.154732e-01</td>\n",
       "      <td>-4.057738e-01</td>\n",
       "      <td>-5.531348e-01</td>\n",
       "      <td>-5.251784e-01</td>\n",
       "      <td>-4.887028e-01</td>\n",
       "      <td>-5.404156e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.475044e-01</td>\n",
       "      <td>-7.938926e-01</td>\n",
       "      <td>-8.406741e-01</td>\n",
       "      <td>-4.869425e-01</td>\n",
       "      <td>-3.630957e-01</td>\n",
       "      <td>-4.366530e-01</td>\n",
       "      <td>-5.785774e-01</td>\n",
       "      <td>-6.414247e-01</td>\n",
       "      <td>-5.748303e-01</td>\n",
       "      <td>-5.858397e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.262693e-01</td>\n",
       "      <td>3.217433e-02</td>\n",
       "      <td>-2.813454e-01</td>\n",
       "      <td>5.937875e-02</td>\n",
       "      <td>1.670512e-01</td>\n",
       "      <td>1.232101e-01</td>\n",
       "      <td>1.923162e-01</td>\n",
       "      <td>1.981733e-01</td>\n",
       "      <td>-1.859469e-01</td>\n",
       "      <td>-2.152131e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.235107e-01</td>\n",
       "      <td>-2.552152e-01</td>\n",
       "      <td>-1.685374e-01</td>\n",
       "      <td>1.714764e-01</td>\n",
       "      <td>-2.411567e-01</td>\n",
       "      <td>-2.855023e-01</td>\n",
       "      <td>-1.498309e-01</td>\n",
       "      <td>-4.150814e-02</td>\n",
       "      <td>1.715063e-02</td>\n",
       "      <td>-1.919589e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.671710e-01</td>\n",
       "      <td>7.411745e-01</td>\n",
       "      <td>4.705533e-01</td>\n",
       "      <td>6.348804e-01</td>\n",
       "      <td>7.225582e-01</td>\n",
       "      <td>5.790645e-01</td>\n",
       "      <td>6.521345e-01</td>\n",
       "      <td>7.187557e-01</td>\n",
       "      <td>4.475620e-02</td>\n",
       "      <td>2.284914e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.125605e-01</td>\n",
       "      <td>4.540541e-01</td>\n",
       "      <td>8.589839e-01</td>\n",
       "      <td>6.244414e-01</td>\n",
       "      <td>-8.428475e-02</td>\n",
       "      <td>4.729295e-02</td>\n",
       "      <td>3.804686e-01</td>\n",
       "      <td>5.835154e-01</td>\n",
       "      <td>5.545250e-01</td>\n",
       "      <td>4.393318e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.733628e+00</td>\n",
       "      <td>1.859925e+00</td>\n",
       "      <td>3.528509e+00</td>\n",
       "      <td>2.904687e+00</td>\n",
       "      <td>1.765232e+00</td>\n",
       "      <td>2.177774e+00</td>\n",
       "      <td>1.913781e+00</td>\n",
       "      <td>2.031541e+00</td>\n",
       "      <td>3.456994e+00</td>\n",
       "      <td>3.538669e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.615370e+00</td>\n",
       "      <td>3.600319e+00</td>\n",
       "      <td>2.476746e+00</td>\n",
       "      <td>2.734528e+00</td>\n",
       "      <td>6.713033e+00</td>\n",
       "      <td>5.465280e+00</td>\n",
       "      <td>6.046893e+00</td>\n",
       "      <td>2.784492e+00</td>\n",
       "      <td>3.338849e+00</td>\n",
       "      <td>4.381477e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Deseq_A1BG-AS1   Deseq_ABHD1  Deseq_ABLIM1  Deseq_ACADVL   Deseq_ACAT2  \\\n",
       "count    1.530000e+02  1.530000e+02  1.530000e+02  1.530000e+02  1.530000e+02   \n",
       "mean     1.960786e-11 -1.307190e-11 -1.437908e-10  6.535935e-12 -1.307190e-11   \n",
       "std      1.003284e+00  1.003284e+00  1.003284e+00  1.003284e+00  1.003284e+00   \n",
       "min     -2.245959e+00 -3.339595e+00 -7.502509e-01 -3.299489e+00 -6.268547e+00   \n",
       "25%     -4.452836e-01 -5.751620e-01 -7.502509e-01 -5.151154e-01 -5.154732e-01   \n",
       "50%      1.262693e-01  3.217433e-02 -2.813454e-01  5.937875e-02  1.670512e-01   \n",
       "75%      6.671710e-01  7.411745e-01  4.705533e-01  6.348804e-01  7.225582e-01   \n",
       "max      2.733628e+00  1.859925e+00  3.528509e+00  2.904687e+00  1.765232e+00   \n",
       "\n",
       "        Deseq_ACOT8    Deseq_ACPT   Deseq_ACSM3    Deseq_ACTB   Deseq_ACTG1  \\\n",
       "count  1.530000e+02  1.530000e+02  1.530000e+02  1.530000e+02  1.530000e+02   \n",
       "mean  -1.307186e-11  3.921568e-11 -2.176908e-18 -1.307195e-11  1.307187e-11   \n",
       "std    1.003284e+00  1.003284e+00  1.003284e+00  1.003284e+00  1.003284e+00   \n",
       "min   -3.645094e+00 -3.262293e+00 -3.484708e+00 -1.769133e+00 -1.277190e+00   \n",
       "25%   -4.057738e-01 -5.531348e-01 -5.251784e-01 -4.887028e-01 -5.404156e-01   \n",
       "50%    1.232101e-01  1.923162e-01  1.981733e-01 -1.859469e-01 -2.152131e-01   \n",
       "75%    5.790645e-01  6.521345e-01  7.187557e-01  4.475620e-02  2.284914e-01   \n",
       "max    2.177774e+00  1.913781e+00  2.031541e+00  3.456994e+00  3.538669e+00   \n",
       "\n",
       "       ...        PDGFBB          VEGF        LEPTIN          PAI1  \\\n",
       "count  ...  1.530000e+02  1.530000e+02  1.530000e+02  1.530000e+02   \n",
       "mean   ... -1.960785e-11 -1.960785e-11  1.960783e-11  1.307188e-11   \n",
       "std    ...  1.003284e+00  1.003284e+00  1.003284e+00  1.003284e+00   \n",
       "min    ... -1.154743e+00 -1.396494e+00 -1.405611e+00 -2.696910e+00   \n",
       "25%    ... -6.475044e-01 -7.938926e-01 -8.406741e-01 -4.869425e-01   \n",
       "50%    ... -2.235107e-01 -2.552152e-01 -1.685374e-01  1.714764e-01   \n",
       "75%    ...  2.125605e-01  4.540541e-01  8.589839e-01  6.244414e-01   \n",
       "max    ...  5.615370e+00  3.600319e+00  2.476746e+00  2.734528e+00   \n",
       "\n",
       "              CD40L         ENA78         CHEX1         CHEX2         CHEX3  \\\n",
       "count  1.530000e+02  1.530000e+02  1.530000e+02  1.530000e+02  1.530000e+02   \n",
       "mean  -6.535961e-12  3.267980e-11  6.535948e-12  4.136125e-17  1.307188e-11   \n",
       "std    1.003284e+00  1.003284e+00  1.003284e+00  1.003284e+00  1.003284e+00   \n",
       "min   -5.872800e-01 -6.024036e-01 -1.598719e+00 -2.600563e+00 -2.992404e+00   \n",
       "25%   -3.630957e-01 -4.366530e-01 -5.785774e-01 -6.414247e-01 -5.748303e-01   \n",
       "50%   -2.411567e-01 -2.855023e-01 -1.498309e-01 -4.150814e-02  1.715063e-02   \n",
       "75%   -8.428475e-02  4.729295e-02  3.804686e-01  5.835154e-01  5.545250e-01   \n",
       "max    6.713033e+00  5.465280e+00  6.046893e+00  2.784492e+00  3.338849e+00   \n",
       "\n",
       "              CHEX4  \n",
       "count  1.530000e+02  \n",
       "mean   5.882351e-11  \n",
       "std    1.003284e+00  \n",
       "min   -2.172262e+00  \n",
       "25%   -5.858397e-01  \n",
       "50%   -1.919589e-01  \n",
       "75%    4.393318e-01  \n",
       "max    4.381477e+00  \n",
       "\n",
       "[8 rows x 1059 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_prediabetic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create prediabetic label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_prediabetic['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_all = pd.concat([DF_control,DF_prediabetic], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_all = DF_all.sample(frac=1,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = DF_all.drop(['SampleID','label'],axis=1)\n",
    "y = DF_all['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([i.split('_')[0] for i in X_train.columns]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for \n",
    "len([i for i in X_train.columns if 'Deseq_' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ML_Pipeline(X_train, y_train,test = False, X_test= None,y_test=None):\n",
    "    #evaluation - baselines\n",
    "    num_folds = 5\n",
    "    seed = 7\n",
    "    scoring = 'f1'\n",
    "    models = []\n",
    "    models.append(('SVC', SVC( class_weight='balanced', max_iter=100)))\n",
    "    models.append(('ET', ExtraTreesClassifier(class_weight='balanced')))\n",
    "    models.append(('LR', LogisticRegression(class_weight='balanced',max_iter=500)))\n",
    "    models.append(('RF', RandomForestClassifier(class_weight='balanced')))\n",
    "    models.append(('GBM', GradientBoostingClassifier(learning_rate=0.001)))\n",
    "\n",
    "    hyperparameters = {\\\n",
    "                       'SVC':{'C': [0.01,0.1,1,10,100], 'kernel':['linear','rbf','poly']},\\\n",
    "                       'ET':{'n_estimators': [50,100,150,200], 'max_depth':[10,50,100]},\\\n",
    "                       'LR':{'C': [0.01,0.1,1,10], 'penalty': ['l1','l2']},\\\n",
    "                       'RF':{'n_estimators': [50,100,150,200], 'max_depth':[10,50,100]},\\\n",
    "                       'GBM': {'n_estimators': [100,500,1000]}}\n",
    "\n",
    "    results = {}\n",
    "    names = []\n",
    "    estimators = {}\n",
    "    print('Model', 'val_mean_score', 'val_std_score')\n",
    "    for name, model in models:\n",
    "        GS = GridSearchCV(model,hyperparameters[name], scoring=scoring, cv=num_folds)\n",
    "        GS_fit = GS.fit(X_train, y_train)\n",
    "        best_index = GS_fit.best_index_\n",
    "        results[name] = pd.DataFrame(GS_fit.cv_results_).drop('params',axis=1).loc[best_index]\n",
    "        estimators[name] = GS_fit.best_estimator_\n",
    "        names.append(name)\n",
    "        msg = (name, pd.DataFrame(GS_fit.cv_results_).drop('params',axis=1).loc[best_index,'mean_test_score'],\\\n",
    "                             pd.DataFrame(GS_fit.cv_results_).loc[best_index,'std_test_score'])\n",
    "        \n",
    "        print(msg)\n",
    "        if test:\n",
    "            print(\"test_score\", f1_score(GS_fit.best_estimator_.predict(X_test),y_test))\n",
    "    # compare algorithms\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Comparison of non-ensemble methods')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(np.array([results[i][[i for i in results[i].index if ('_test_score' in i) & ('split' in i)]].values for i in names  ]).T)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "\n",
    "    return pd.DataFrame(results), estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model val_mean_score val_std_score\n",
      "('SVC', 0.930386899613677, 0.0071882912532388946)\n",
      "test_score 0.92\n",
      "('ET', 0.934523388712148, 0.012906977943671844)\n",
      "test_score 0.9292929292929293\n",
      "('LR', 0.7724122969810061, 0.06827021856956601)\n",
      "test_score 0.5974025974025974\n",
      "('RF', 0.9773580005003714, 0.014350168978372078)\n",
      "test_score 0.968421052631579\n",
      "('GBM', 0.9687259036392184, 0.02235585875013341)\n",
      "test_score 0.9583333333333334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(                            SVC          ET           LR           RF  \\\n",
       " mean_fit_time         0.0143976   0.0481996    0.0129984    0.0622063   \n",
       " mean_score_time      0.00379925  0.00259852   0.00140257   0.00360045   \n",
       " mean_test_score        0.930387    0.934523     0.772412     0.977358   \n",
       " mean_train_score              1           1            1            1   \n",
       " param_C                       1         NaN           10          NaN   \n",
       " param_kernel                rbf         NaN          NaN          NaN   \n",
       " param_max_depth             NaN         100          NaN           10   \n",
       " param_n_estimators          NaN          50          NaN           50   \n",
       " param_penalty               NaN         NaN           l1          NaN   \n",
       " rank_test_score               1           1            1            1   \n",
       " split0_test_score      0.916667    0.916667     0.844444     0.977778   \n",
       " split0_train_score            1           1            1            1   \n",
       " split1_test_score       0.93617    0.956522     0.717949            1   \n",
       " split1_train_score            1           1            1            1   \n",
       " split2_test_score      0.933333    0.933333     0.666667     0.976744   \n",
       " split2_train_score            1           1            1            1   \n",
       " split3_test_score      0.933333    0.933333          0.8     0.954545   \n",
       " split3_train_score            1           1            1            1   \n",
       " split4_test_score      0.933333    0.933333     0.829268     0.976744   \n",
       " split4_train_score            1           1            1            1   \n",
       " std_fit_time        0.000489535  0.00160129    0.0010962   0.00613652   \n",
       " std_score_time       0.00040057  0.00049105  0.000491868  0.000802746   \n",
       " std_test_score       0.00718829    0.012907    0.0682702    0.0143502   \n",
       " std_train_score               0           0            0            0   \n",
       " \n",
       "                             GBM  \n",
       " mean_fit_time             3.466  \n",
       " mean_score_time      0.00120683  \n",
       " mean_test_score        0.968726  \n",
       " mean_train_score              1  \n",
       " param_C                     NaN  \n",
       " param_kernel                NaN  \n",
       " param_max_depth             NaN  \n",
       " param_n_estimators         1000  \n",
       " param_penalty               NaN  \n",
       " rank_test_score               1  \n",
       " split0_test_score      0.956522  \n",
       " split0_train_score            1  \n",
       " split1_test_score             1  \n",
       " split1_train_score            1  \n",
       " split2_test_score      0.976744  \n",
       " split2_train_score            1  \n",
       " split3_test_score      0.933333  \n",
       " split3_train_score            1  \n",
       " split4_test_score      0.976744  \n",
       " split4_train_score            1  \n",
       " std_fit_time           0.108202  \n",
       " std_score_time      0.000398166  \n",
       " std_test_score        0.0223559  \n",
       " std_train_score               0  ,\n",
       " {'ET': ExtraTreesClassifier(bootstrap=False, class_weight='balanced',\n",
       "             criterion='gini', max_depth=100, max_features='auto',\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "             verbose=0, warm_start=False),\n",
       "  'GBM': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                learning_rate=0.001, loss='deviance', max_depth=3,\n",
       "                max_features=None, max_leaf_nodes=None,\n",
       "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                min_samples_leaf=1, min_samples_split=2,\n",
       "                min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "                warm_start=False),\n",
       "  'LR': LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=500,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'RF': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "              criterion='gini', max_depth=10, max_features='auto',\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False),\n",
       "  'SVC': SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=100, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)})"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results, Models = ML_Pipeline(X_train,y_train,test=True,X_test= X_test,y_test = y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
